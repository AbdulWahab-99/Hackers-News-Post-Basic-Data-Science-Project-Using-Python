{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332ffd3b",
   "metadata": {},
   "source": [
    "# Work with a data set of submissions to Hacker News\n",
    "\n",
    "## Background\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "We'll be examining two types of posts from Hacker News. Ask HN are posts that users submit to ask the Hacker News community a specific question. Show HN are posts by users to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll compare Ask HN and Show HN to answer the following questions:\n",
    "\n",
    "A. Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "\n",
    "B. Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "C. Do either `Ask HN` or `Show HN` receive more points?\n",
    "\n",
    "D. During which hours are the posts more likely to receive higher points?\n",
    "\n",
    "\n",
    "\n",
    "## Step 1: Opening and Exploring the Data\n",
    "\n",
    "You can find the data set at Kaggle here, but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "id: The unique identifier from Hacker News for the post\n",
    "title: The title of the post\n",
    "url: The URL that the posts links to, if it the post has a URL\n",
    "num_points: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "num_comments: The number of comments that were made on the post\n",
    "author: The username of the person who submitted the post \n",
    "created_at: The date and time at which the post was submitted\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists, hn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638476cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "opened_file = open(\"hacker_news.csv\",encoding = \"utf-8\")\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0868e",
   "metadata": {},
   "source": [
    "We notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row.\n",
    "\n",
    "## Step 2: In order to analyze our data, we'll remove the first row of column headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0b47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "header = hn[0]\n",
    "hn = hn[1:]\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bcc6a1",
   "metadata": {},
   "source": [
    "Now that we've removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles.\n",
    "\n",
    "## Step 3: Filter our data to find the posts we're interested in\n",
    "\n",
    "To find the posts that begin with either Ask HN or Show HN, we'll use the string method startswith. Given a string object, say, string1, we can check if starts with, say, dq by inspecting the output of the object string1.startswith('dq'). If string1 starts with dq, it will return True, otherwise it will return False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9217f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('dataquest'.startswith('Data'))\n",
    "print('dataquest'.startswith('data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbf79a",
   "metadata": {},
   "source": [
    "In the example above, the first print call gives us False because dataquest does not start with Data. The second print call prints True because dataquest does start with data. Capitalization matters.\n",
    "\n",
    "If we wish to control for case, we can use the lower method which returns a lowercase version of the starting string. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b374445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataquest\n"
     ]
    }
   ],
   "source": [
    "print('DataQuest'.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637b787",
   "metadata": {},
   "source": [
    "Let's use these methods to separate posts beginning with Ask HN and Show HN (and case variations) into two different lists next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a1919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ask posts: 1744\n",
      "Total number of show posts: 1162\n",
      "Total number of other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(\"Total number of ask posts:\", len(ask_posts))\n",
    "print(\"Total number of show posts:\", len(show_posts))\n",
    "print(\"Total number of other posts:\", len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f958ca",
   "metadata": {},
   "source": [
    "Above, we separated the \"ask posts\" and the \"show posts\" into two list of lists named ask_posts and show_posts.\n",
    "\n",
    "We note that the majority of posts falls into the category of other posts. It might be of interest if we wanted to extend our sample to have a further look. For the moment, we will accept the results and work with our filtered data.\n",
    "\n",
    "Below are the first five rows for each of the list of lists ask_posts and show_posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a367cc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6726f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11'], ['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']]\n"
     ]
    }
   ],
   "source": [
    "print(show_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88572e16",
   "metadata": {},
   "source": [
    "## Step 4: Determine if ask posts or show posts receive more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dcf89c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d11499",
   "metadata": {},
   "source": [
    "### Answer A: Our calculation indicates that on average, ask hn posts receive more comments.\n",
    "\n",
    "Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "## Step 5. Determine if there is a certain time ask posts are more likely to attract comments.\n",
    "We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts received by hour created.\n",
    "\n",
    "We'll use datetime to work with the data in the created_at column. Note that the time data is EST, we'll use that information later to calculate the best time to create posts in our own timezone.\n",
    "\n",
    "Below, we'll create a two element list corresponding to the time data and comments. This will allow us to focus on the information necessary to build a frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba3c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29], ['5/2/2016 10:14', 1], ['8/2/2016 14:20', 3]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    in_list = [created_at, num_comments]\n",
    "    result_list.append(in_list)\n",
    "print(result_list[:4])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720ab4b",
   "metadata": {},
   "source": [
    "We can now create the frequency table with the date and comments data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e33c437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    dt_object = row[0]\n",
    "    dt_parsed = dt.datetime.strptime(dt_object, \"%m/%d/%Y %H:%M\")\n",
    "    hr = dt.datetime.strftime(dt_parsed, \"%H\")\n",
    "    # print(hr)\n",
    "\n",
    "    if hr not in counts_by_hour:\n",
    "        counts_by_hour[hr] = 1\n",
    "        comments_by_hour[hr] = int(row[1])\n",
    "    else:\n",
    "        counts_by_hour[hr] = counts_by_hour[hr] + 1\n",
    "        comments_by_hour[hr] = comments_by_hour[hr] + int(row[1])\n",
    "\n",
    "print(comments_by_hour)\n",
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6de083",
   "metadata": {},
   "source": [
    "## Step 6: Average number of comments in an hour\n",
    "\n",
    "We can now use these two dictionaries to calculate the average number of comments for posts created during each hour of the day. Below, we will build a list of lists containing the hours during which posts were created and the average number of comments those posts received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b275805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cb225",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values.\n",
    "\n",
    "## Step 7: Sort the list of lists and print the five highest values so it's easier to read\n",
    "\n",
    "We'll swap the elements to display the average by hour below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04128a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2c102",
   "metadata": {},
   "source": [
    "Now we can find the top 5 hours for posting comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf46036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for row in sorted_swap[:5]:\n",
    "    hr_obj = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hr_obj_string = dt.datetime.strftime(hr_obj, \"%H:%M\")\n",
    "    Template = \"{}: {:.2f} average comments per post.\"\n",
    "    print(Template.format(hr_obj_string, row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d86e9",
   "metadata": {},
   "source": [
    "### Answer B: On average, the majority of comments are created at 15:00 EST.\n",
    "\n",
    "As previously noted, the above times are in EST (Eastern Standard Time). For my Pakistan Standard Time, I should post 9 hours ahead (depending on daylight savings time which is different for my time zone as well). So if I create posts at 00:00, 11:00, 5:00, 01:00, and 12:00 I will have the best chance for highest comment rate per hour.\n",
    "\n",
    "## Step 8: Find out if either Ask HN or Show HN receive more points\n",
    "\n",
    "To know this, we will calculate the average number of points received by Ask and Show posts, in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95d4d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average like or points per ask post: 15.061926605504587\n",
      "Average like or points per show post: 27.555077452667813\n"
     ]
    }
   ],
   "source": [
    "total_ask_points = 0\n",
    "for row in ask_posts:\n",
    "    num_points = int(row[3])\n",
    "    total_ask_points += num_points\n",
    "avg_ask_points = total_ask_points/len(ask_posts)\n",
    "\n",
    "total_show_points = 0\n",
    "for row in show_posts:\n",
    "    num_points = int(row[3])\n",
    "    total_show_points += num_points\n",
    "avg_show_points = total_show_points/len(show_posts)\n",
    "print(\"Average like or points per ask post:\",avg_ask_points)\n",
    "print(\"Average like or points per show post:\",avg_show_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204cfa1a",
   "metadata": {},
   "source": [
    "### Answer C: We've determined that Show HN posts receive more points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72007776",
   "metadata": {},
   "source": [
    "## Step 9: During which hours are Show HN posts more likely to receive higher points\n",
    "\n",
    "As the average number of points per Show HN post is greater, we will continue our analysis on the times that they are most likely to receive higher points.\n",
    "\n",
    "We'll now construct a list to hold the data we're interested in - similar to what we did previously for ask_posts in Step 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f318c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['11/25/2015 14:03', 26], ['11/29/2015 22:46', 747], ['4/28/2016 18:05', 1], ['7/28/2016 7:11', 3]]\n"
     ]
    }
   ],
   "source": [
    "show_result_list = []\n",
    "for row in show_posts:\n",
    "    created_at = row[6]\n",
    "    num_points = int(row[3])\n",
    "    show_result_list.append([created_at, num_points])\n",
    "print(show_result_list[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4582d55",
   "metadata": {},
   "source": [
    "We can now create the frequency table with the date and posts data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c78fdb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': 86, '22': 46, '18': 61, '07': 26, '20': 60, '05': 19, '16': 93, '19': 55, '15': 78, '03': 27, '17': 93, '06': 16, '02': 30, '13': 99, '08': 34, '21': 47, '04': 26, '11': 44, '12': 61, '23': 36, '09': 30, '01': 28, '10': 36, '00': 31}\n",
      "{'14': 2187, '22': 1856, '18': 2215, '07': 494, '20': 1819, '05': 104, '16': 2634, '19': 1702, '15': 2228, '03': 679, '17': 2521, '06': 375, '02': 340, '13': 2438, '08': 519, '21': 866, '04': 386, '11': 1480, '12': 2543, '23': 1526, '09': 553, '01': 700, '10': 681, '00': 1173}\n"
     ]
    }
   ],
   "source": [
    "counts_by_show_hours = {}\n",
    "points_by_hours = {}\n",
    "for row in show_result_list:\n",
    "    dt_object = row[0]\n",
    "    dt_parsed = dt.datetime.strptime(dt_object,\"%m/%d/%Y %H:%M\")\n",
    "    hr = dt.datetime.strftime(dt_parsed, \"%H\")\n",
    "    if hr not in counts_by_show_hours:\n",
    "        counts_by_show_hours[hr] = 1\n",
    "        points_by_hours[hr] = row[1]\n",
    "    else:\n",
    "        counts_by_show_hours[hr] += 1\n",
    "        points_by_hours[hr] += row[1]\n",
    "print(counts_by_show_hours)\n",
    "print(points_by_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e94bb",
   "metadata": {},
   "source": [
    "## Step 10: Average number of points for show post in any hour\n",
    "\n",
    "We can now use these two dictionaries for our calculation, very similar to Step 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbf8b335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['14', 25.430232558139537], ['22', 40.34782608695652], ['18', 36.31147540983606], ['07', 19.0], ['20', 30.316666666666666], ['05', 5.473684210526316], ['16', 28.322580645161292], ['19', 30.945454545454545], ['15', 28.564102564102566], ['03', 25.14814814814815], ['17', 27.107526881720432], ['06', 23.4375], ['02', 11.333333333333334], ['13', 24.626262626262626], ['08', 15.264705882352942], ['21', 18.425531914893618], ['04', 14.846153846153847], ['11', 33.63636363636363], ['12', 41.68852459016394], ['23', 42.388888888888886], ['09', 18.433333333333334], ['01', 25.0], ['10', 18.916666666666668], ['00', 37.83870967741935]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_show_hour = []\n",
    "for hour in points_by_hours:\n",
    "    avg_by_show_hour.append([hour, points_by_hours[hour]/counts_by_show_hours[hour]])\n",
    "print(avg_by_show_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf349765",
   "metadata": {},
   "source": [
    "## Step 11: Sort the list of lists and print the five highest values so it's easier to read\n",
    "\n",
    "We'll swap the elements as in Step 7 and arrange them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffe7a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25.430232558139537, '14'],\n",
       " [40.34782608695652, '22'],\n",
       " [36.31147540983606, '18'],\n",
       " [19.0, '07'],\n",
       " [30.316666666666666, '20'],\n",
       " [5.473684210526316, '05'],\n",
       " [28.322580645161292, '16'],\n",
       " [30.945454545454545, '19'],\n",
       " [28.564102564102566, '15'],\n",
       " [25.14814814814815, '03'],\n",
       " [27.107526881720432, '17'],\n",
       " [23.4375, '06'],\n",
       " [11.333333333333334, '02'],\n",
       " [24.626262626262626, '13'],\n",
       " [15.264705882352942, '08'],\n",
       " [18.425531914893618, '21'],\n",
       " [14.846153846153847, '04'],\n",
       " [33.63636363636363, '11'],\n",
       " [41.68852459016394, '12'],\n",
       " [42.388888888888886, '23'],\n",
       " [18.433333333333334, '09'],\n",
       " [25.0, '01'],\n",
       " [18.916666666666668, '10'],\n",
       " [37.83870967741935, '00']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_show_avg_by_hour = []\n",
    "for row in avg_by_show_hour:\n",
    "    swap_show_avg_by_hour.append([row[1],row[0]])\n",
    "swap_show_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8076264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for SHow Posts Comments\n",
      "23:00: 42.39 average Likes or Points per post.\n",
      "12:00: 41.69 average Likes or Points per post.\n",
      "22:00: 40.35 average Likes or Points per post.\n",
      "00:00: 37.84 average Likes or Points per post.\n",
      "18:00: 36.31 average Likes or Points per post.\n"
     ]
    }
   ],
   "source": [
    "swap_sorted = sorted(swap_show_avg_by_hour, reverse = True)\n",
    "\n",
    "print(\"Top 5 Hours for SHow Posts Comments\")\n",
    "for row in swap_sorted[:5]:\n",
    "    hr_obj = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hr_obj_string = dt.datetime.strftime(hr_obj, \"%H:%M\")\n",
    "    Template = \"{}: {:.2f} average Likes or Points per post.\"\n",
    "    print(Template.format(hr_obj_string, row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90dd0a0",
   "metadata": {},
   "source": [
    "### Answer D: The best time for a show HN post is at 23:00 EST.\n",
    "\n",
    "The times listed above are in Eastern Standard Time, so for Central European Time we'll advance 9 hours.\n",
    "\n",
    "8:00, 21:00, and 7:00 are the best times, followed by 9:00 and 3:00, to acquire the highest likes or point totals.\n",
    "\n",
    "## Summary\n",
    "To summarize our results:\n",
    "\n",
    "A. Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "\n",
    "    ### Our calculation indicates that on average, `Ask HN` posts receive more comments (14 vs 10).\n",
    "\n",
    "B. Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "    ### On average, the majority of comments are created at 15:00 EST.\n",
    "\n",
    "C. Do either `Ask HN` or `Show HN` receive more points?\n",
    "\n",
    "    ### `Show HN` posts receive more points (27 points vs. 15 for `Ask HN`)\n",
    "\n",
    "D. During which hours are the posts more likely to receive higher points?\n",
    "\n",
    "    ### The most points are received by posts created at 23:00, followed closely by those at 12:00 and 22:00"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
